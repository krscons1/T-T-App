#!/usr/bin/env python3
"""
Test script to demonstrate the audio cross-validation system.
This shows how the system uses speech recognition models to compare transcripts with actual audio.
"""

import asyncio
import json
from app.services.audio_cross_validator import audio_cross_validator

# Sample data based on your example
SAMPLE_DATA = {
    "transcript1": "Let me sing a ‡Æï‡ØÅ‡Æü‡Øç‡Æü‡Æø ‡Æ∏‡Øç‡Æü‡Øã‡Æ∞‡Æø, pay attention, listen to me.  ‡Æé‡Æ©‡Øç‡Æ© ‡Æ®‡Ææ‡Æ©‡Øç ‡Æá‡Æô‡Øç‡Æï‡Æø‡Æ≤‡ØÄ‡Æ∑‡Øç? Just listen bro.  ‡Æ™‡Æ≤‡Æµ‡Æø‡Æ§ problems will come and go. ‡Æï‡Øä‡Æû‡Øç‡Æö‡ÆÆ‡Øç ‡Æú‡Æø‡Æ≤‡Øç ‡Æ™‡Æ£‡Øç‡Æ£‡ØÅ ‡ÆÆ‡Ææ‡Æ™‡Øç‡Æ™‡Æø. Together man.",
    "transcript2": "Let me sing a good story, pay attention listen to me.\n No no he is listening.\n Just listen.\nLet me sing a good story, pay attention listen to me.\nIf you want take guitar or smell attention leave it baby.\nLife is very short ‡Æ®‡Æ£‡Øç‡Æ™‡Ææ. Always be happy.\n‡Æ™‡Æ≤‡Æµ‡Æø‡Æ§ problems will come and go.\n‡Æï‡Øä‡Æû‡Øç‡Æö‡ÆÆ‡Øç ‡Æú‡ØÄ‡Æµ‡Æ©‡ÆÆ‡Ææ ‡Æ™‡ØÄ.\nTogether man.",
    "audio_file1": "C:\\Users\\LENOVO\\Desktop\\T-Tamil\\T-T-App\\backend\\downloads\\1751705376_Kutti-Story-MassTamilan.io_converted.wav",
    "audio_file2": "C:\\Users\\LENOVO\\Desktop\\T-Tamil\\T-T-App\\backend\\downloads\\1751705376_Kutti-Story-MassTamilan.io_speech.wav"
}

async def test_audio_cross_validation():
    """Test the audio cross-validation system"""
    print("üß™ Testing Audio Cross-Validation System")
    print("=" * 50)
    
    print("\n1Ô∏è‚É£ Loading speech recognition models...")
    print("   ‚Ä¢ Whisper model for word-level validation")
    print("   ‚Ä¢ Wav2Vec2 model for segment-level validation")
    
    # Test audio cross-validation
    print("\n2Ô∏è‚É£ Performing audio cross-validation...")
    try:
        validation_result = await audio_cross_validator.cross_validate_with_audio(
            SAMPLE_DATA["transcript1"],
            SAMPLE_DATA["transcript2"],
            SAMPLE_DATA["audio_file1"],
            SAMPLE_DATA["audio_file2"]
        )
        
        if 'error' in validation_result:
            print(f"‚ùå Audio cross-validation failed: {validation_result['error']}")
            print("üí° This is expected if audio files don't exist or models aren't loaded")
        else:
            print("‚úÖ Audio cross-validation completed successfully!")
            
            # Show word-level validation results
            word_validation = validation_result.get('word_validation', {})
            word_confidence_scores = word_validation.get('word_confidence_scores', {})
            
            print(f"\n3Ô∏è‚É£ Word-Level Validation Results:")
            print(f"   ‚Ä¢ Total words analyzed: {len(word_confidence_scores)}")
            print(f"   ‚Ä¢ Pipeline 1 correct words: {len(word_validation.get('pipeline1_correct_words', []))}")
            print(f"   ‚Ä¢ Pipeline 2 correct words: {len(word_validation.get('pipeline2_correct_words', []))}")
            print(f"   ‚Ä¢ Uncertain words: {len(word_validation.get('uncertain_words', []))}")
            
            # Show some example word validations
            print(f"\nüìù Example Word Validations:")
            for i, (word_id, confidence_data) in enumerate(list(word_confidence_scores.items())[:5]):
                word1 = confidence_data.get('pipeline1_word', '')
                word2 = confidence_data.get('pipeline2_word', '')
                conf1 = confidence_data.get('pipeline1_confidence', 0)
                conf2 = confidence_data.get('pipeline2_confidence', 0)
                
                print(f"   ‚Ä¢ Word {word_id}: '{word1}' (conf: {conf1:.2f}) vs '{word2}' (conf: {conf2:.2f})")
                if conf1 > conf2:
                    print(f"     ‚Üí Pipeline 1 is more confident")
                elif conf2 > conf1:
                    print(f"     ‚Üí Pipeline 2 is more confident")
                else:
                    print(f"     ‚Üí Similar confidence")
            
            # Show segment-level validation results
            segment_validation = validation_result.get('segment_validation', {})
            segment_analysis = segment_validation.get('segment_analysis', {})
            
            print(f"\n4Ô∏è‚É£ Segment-Level Validation Results:")
            print(f"   ‚Ä¢ Total segments analyzed: {len(segment_analysis)}")
            print(f"   ‚Ä¢ Pipeline 1 correct segments: {len(segment_validation.get('pipeline1_correct_segments', []))}")
            print(f"   ‚Ä¢ Pipeline 2 correct segments: {len(segment_validation.get('pipeline2_correct_segments', []))}")
            
            # Show optimal transcript
            optimal_transcript = validation_result.get('optimal_transcript', '')
            print(f"\n5Ô∏è‚É£ Optimal Transcript (Audio Cross-Validated):")
            print(f"   ‚Ä¢ Length: {len(optimal_transcript)} characters")
            print(f"   ‚Ä¢ Word count: {len(optimal_transcript.split())} words")
            print(f"\nüìù Preview:")
            print(f"   {optimal_transcript[:200]}...")
            
            # Show audio analysis
            audio_analysis = validation_result.get('audio_analysis', {})
            print(f"\n6Ô∏è‚É£ Audio Analysis:")
            print(f"   ‚Ä¢ Audio 1 duration: {audio_analysis.get('audio1_duration', 0):.2f}s")
            print(f"   ‚Ä¢ Audio 2 duration: {audio_analysis.get('audio2_duration', 0):.2f}s")
            print(f"   ‚Ä¢ Sample rate: {audio_analysis.get('sample_rate', 0)} Hz")
    
    except Exception as e:
        print(f"‚ùå Audio cross-validation error: {e}")
        print("üí° This is expected in test environment without actual audio files")
    
    print(f"\nüéØ Key Features of Audio Cross-Validation:")
    print("   ‚Ä¢ Uses Whisper model for word-level audio validation")
    print("   ‚Ä¢ Uses Wav2Vec2 model for segment-level audio validation")
    print("   ‚Ä¢ Compares each word/segment with actual audio")
    print("   ‚Ä¢ Chooses the most confident transcription for each word")
    print("   ‚Ä¢ Creates optimal transcript based on audio evidence")
    print("   ‚Ä¢ No manual corrections - everything based on audio analysis")

if __name__ == "__main__":
    asyncio.run(test_audio_cross_validation()) 